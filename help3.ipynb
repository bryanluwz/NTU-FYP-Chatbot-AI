{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from src.functions import initialize_llm, initialize_qa_chain, create_and_save_vector_store, load_embeddings_model, load_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model path: c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\models\\embedding_model\n",
      "Vector store path: c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\models\\vector_store\n",
      "LLM Model path: c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\models\\llm_model\n",
      "Loading documents from directory: c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\documents\\HW0288\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "MODEL_NAME = 'meta-llama/Llama-3.2-1B'\n",
    "# MODEL_NAME = 'distilgpt2'\n",
    "EMBEDDING_NAME = 'sentence-transformers/paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "EMBEDDING_MODEL_PATH = os.path.abspath(config.get(\n",
    "    'EMBEDDING_MODEL_PATH', './models/embedding_model'))\n",
    "\n",
    "VECTOR_STORE_PATH = os.path.abspath(config.get(\n",
    "    'VECTOR_STORE_PATH', './models/vector_store'))\n",
    "\n",
    "LLM_MODEL_PATH = os.path.abspath(\n",
    "    config.get('LLM_MODEL_PATH', './models/model'))\n",
    "\n",
    "print(\"Embedding model path:\", EMBEDDING_MODEL_PATH)\n",
    "print(\"Vector store path:\", VECTOR_STORE_PATH)\n",
    "print(\"LLM Model path:\", LLM_MODEL_PATH)\n",
    "\n",
    "DOCUMENT_PARENT_DIR_PATH = os.path.abspath(\n",
    "    config.get('DOCUMENT_DIR_PATH', './documents'))\n",
    "DOCUMENT_DIR_NAME = 'HW0288'\n",
    "DOCUMENT_DIR_PATH = os.path.join(DOCUMENT_PARENT_DIR_PATH, DOCUMENT_DIR_NAME)\n",
    "\n",
    "print(\"Loading documents from directory:\", DOCUMENT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded vector store from local storage.\n"
     ]
    }
   ],
   "source": [
    "embeddings = load_embeddings_model(\n",
    "    EMBEDDING_NAME, embedding_model_path=EMBEDDING_MODEL_PATH)\n",
    "\n",
    "vector_store_path = os.path.join(\n",
    "    VECTOR_STORE_PATH, f\"{DOCUMENT_DIR_NAME}_{embeddings.model_name}\")\n",
    "\n",
    "file_paths = [os.path.join(DOCUMENT_DIR_PATH, filepath)\n",
    "              for filepath in os.listdir(DOCUMENT_DIR_PATH)]\n",
    "file_paths_abs = [os.path.abspath(file_path) for file_path in file_paths]\n",
    "\n",
    "vector_store = load_vector_store(embeddings, vector_store_path)\n",
    "\n",
    "if vector_store is None:\n",
    "    vector_store = create_and_save_vector_store(\n",
    "        embeddings, vector_store_path, file_paths_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading model from c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\models\\llm_model\\meta-llama/Llama-3.2-1B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: MAKE SURE YOU'RE AUTHENTICATED AND HAVE ACCESS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "custom_prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Persona:\n",
    "You are an AI model that provides short, concise answers.\n",
    "If you do not know the answer, respond with \"I don't know.\"\n",
    "If the question is not relevant to the context, respond with \"Not relevant.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{input}\n",
    "\n",
    "Provide only the answer, nothing else:\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "llm = initialize_llm(model_name=MODEL_NAME,\n",
    "                     max_new_tokens=512, model_path=LLM_MODEL_PATH)\n",
    "\n",
    "qa_chain = initialize_qa_chain(\n",
    "    llm, vector_store, prompt_template=custom_prompt_template, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaf88cac7d24f109424bd47a47d2481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryan\\Documents\\GitHub\\NTU-FYP-Chatbot-AI\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Answer ======\n",
      "Assignment 1 is due on 5th December 2021. \n",
      "\n",
      "Please do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not use any references in your assignment. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to\n"
     ]
    }
   ],
   "source": [
    "query = \"When is assignment 1 due?\"\n",
    "\n",
    "result = qa_chain.invoke({\n",
    "    \"input\": query,\n",
    "})\n",
    "\n",
    "print(\"====== Answer ======\")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When is assignment 1 due?\n",
      " ===== Answer ===== \n",
      "Assignment 1 is due on 5th December 2021. \n",
      "\n",
      "Please do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not use any references in your assignment. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to Turnitin. \n",
      "\n",
      "Do not submit the assignment to\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "print(\" ===== Answer ===== \")\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
